{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Convolutional neural networks are highly effective for image classification and recognition tasks, as they employ a variety of filters in each layer to learn features from the training images. The features that are learned at each convolutional layer tend to vary significantly. It has been observed that the earlier layers tend to capture low-level features such as edges, orientation, and colors in the image. As the number of layers increases, the CNN is able to capture more high-level features, which aid in distinguishing between different classes of images. To better understand how convolutional neural networks learn spatial and temporal dependencies in images, it is possible to visualize the different features that are captured at each layer.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To experiment the visualization of the output of CNN layers, We will consider a Binary Classification (dog and cat image classification) Task where we build a convolutional neural network and then add a classifier on top of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Step-1: Loading a dataset and preprocessing the data\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(\"data/processed_data/train\", target_size=(150,150), batch_size=20, class_mode=\"binary\")\n",
    "validation_generator = val_data_gen.flow_from_directory(\"data/processed_data/test\", target_size=(150,150), batch_size=20, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step-2: Define the model architecture\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu' ))\n",
    "model.add(layers.MaxPool2D( (2,2) ) )\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu' ))\n",
    "model.add(layers.MaxPool2D( (2,2) ) )\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu' ))\n",
    "model.add(layers.MaxPool2D( (2,2) ) )\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # paramer of each layer =  weight [32(num of filters)*3*3(filter size)* 3(channel)] + baise[num of filters]\n",
    "\n",
    "# output shape ( 150-3+1, 150-3+1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introtodeepln",
   "language": "python",
   "name": "introtodeepln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
